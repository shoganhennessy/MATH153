---
title: "MATH153, Lab 1"
author: "Senan Hogan-H."
date: "25 January 25 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
gc()
ls()
options(digits=4)
require(tidyverse)
set.seed(47)
```

## Question 1.

a.

```{r}
p_hat <- c() #initialize the vector that I will fill in with the partial sums
p_value <- c()
p = c(0:10)/10 # Vector of p values to try over
n = c(1:1000) #Vector of sample size to repeat over
for (k in p) {
  for (i in n) {
    p_i <- mean(rbinom(1000, i, k))/i
    p_hat <- c(p_hat, p_i)
    p_value <- c(p_value, k)
  }
}
P.data <- data.frame(n, p_hat, p_value)
P.data %>% ggplot(aes(n, p_hat, col=p_value)) +
                    geom_point() + ylim(0, 1)
```
$$ E[ \hat{p} ]= E[\frac{\sum_{i=1}^n X_i}{n}]=\frac{1}{n}\sum_{i=1}^n X_i=\frac{1}{n}pn=p$$.
So that $\hat{p}$ is unbiased in general, and so sample size does not matter for this small-sample property.

b. 
```{r}
p_i <- p_0.1 <- p_0.25 <- p_0.5 <- p_0.75 <- p_0.9 <- c() 
n = c(1:1000) #Vector of sample size to repeat over
for (i in n) {
  p_i <- mean(rbinom(1, i, 0.1))/i
  p_0.1 <- c(p_0.1, p_i)
}
for (i in n) {
  p_i <- mean(rbinom(1, i, 0.25))/i
  p_0.25 <- c(p_0.25, p_i)
}
for (i in n) {
  p_i <- mean(rbinom(1, i, 0.5))/i
  p_0.5 <- c(p_0.5, p_i)
}
for (i in n) {
  p_i <- mean(rbinom(1, i, 0.75))/i
  p_0.75 <- c(p_0.75, p_i)
}
for (i in n) {
  p_i <- mean(rbinom(1, i, 0.9))/i
  p_0.9 <- c(p_0.9, p_i)
}

P.data <- data.frame(n, p_0.1 , p_0.25 , p_0.5 , p_0.75 , p_0.9)
P.data %>% ggplot(aes(n)) +
  geom_line(aes(y = p_0.1, colour = "p = 0.1")) +
  geom_line(aes(y = p_0.25, colour = "p = 0.25")) +
  geom_line(aes(y = p_0.5, colour = "p = 0.5")) +
  geom_line(aes(y = p_0.75, colour = "p = 0.75")) +
  geom_line(aes(y = p_0.9, colour = "p = 0.9")) +
  ylim(0, 1) + ylab('p hat')
```


## Question 2.

First part.
```{r}
p=0.25
n=200
p_hat_25=c()
for (i in 1: n) {
x = rbinom(1000,i,p)
p_hat_25=c(p_hat_25,sd(x)/i)}

p=0.5
n=200
p_hat_5=c()
for (i in 1: n) {
x = rbinom(1000,i,p)
p_hat_5=c(p_hat_5,sd(x)/i)}


p=0.75
n=200
p_hat_75=c()
for (i in 1: n) {
x = rbinom(1000,i,p)
p_hat_75=c(p_hat_75,sd(x)/i)}


n=200
root=c()
for (i in 1:n){
x=1/sqrt(i)
root=c(root,x)}


P.data <- data.frame(1:n, p_hat_25 , p_hat_5 , p_hat_75 , root)
P.data %>% ggplot(aes(1:n)) +
  geom_line(aes(y = p_hat_25, colour = "p = 0.25")) +
  geom_line(aes(y = p_hat_5, colour = "p = 0.5")) +
  geom_line(aes(y = p_hat_75, colour = "p = 0.75")) +
  geom_line(aes(y = root, colour = "1/sqrt(n)")) +
  ylim(0, 1) + ylab('standard deviation of p_hat') + xlab('Sample Size, n')
```

Second Part.
```{r}
p <- 0.02  
n <- 200
cornorm_02 <- c()
for (i in 1 : n) {
  p_hat <- rbinom(1000,i,p)/i
  b <- qqnorm(p_hat, plot.it=FALSE)
  cornorm_02[i] <- cor(b$x,b$y)
}

p <- 0.25  
n <- 200
cornorm_25 <- c()
for (i in 1 : n) {
  p_hat <- rbinom(1000,i,p)/i
  b <- qqnorm(p_hat, plot.it=FALSE)
  cornorm_25[i] <- cor(b$x,b$y)
}

p <- 0.5  
n <- 200
cornorm_5 <- c()
for (i in 1 : n) {
  p_hat <- rbinom(1000,i,p)/i
  b <- qqnorm(p_hat, plot.it=FALSE)
  cornorm_5[i] <- cor(b$x,b$y)
}


p <- 0.75  
n <- 200
cornorm_75 <- c()
for (i in 1 : n) {
  p_hat <- rbinom(1000,i,p)/i
  b <- qqnorm(p_hat, plot.it=FALSE)
  cornorm_75[i] <- cor(b$x,b$y)
}

p <- 0.98  
n <- 200
cornorm_98 <- c()
for (i in 1 : n) {
  p_hat <- rbinom(1000,i,p)/i
  b <- qqnorm(p_hat, plot.it=FALSE)
  cornorm_98[i] <- cor(b$x,b$y)
}

P.data <- data.frame(1:n, cornorm_02 , cornorm_25 , cornorm_5 , cornorm_75, cornorm_98)
P.data %>% ggplot(aes(1:n)) +
  geom_line(aes(y = cornorm_02, colour = "p = 0.02")) +
  geom_line(aes(y = cornorm_25, colour = "p = 0.25")) +
  geom_line(aes(y = cornorm_5, colour = "p = 0.5")) +
  geom_line(aes(y = cornorm_75, colour = "p = 0.75")) +
  geom_line(aes(y = cornorm_98, colour = "p = 0.98")) +
  ylim(0, 1) + ylab('correlation with normal') + xlab('Sample Size, n')
```

## Question 3.
```{r, fig.height = 3, fig.width = 6.5, fig.align='center'}
#First p-value
p = 0.1

#first n value
n <- 10
p_hatb_10 <- p_hat_10 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_10 <- c((sum(x_i)+10)/(n+20), p_hatb_10) 
  p_hat_10 <- c(mean(x_i), p_hat_10)
}
# second n value
n <- 100
p_hatb_100 <- p_hat_100 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_100 <- c((sum(x_i)+10)/(n+20), p_hatb_100) 
  p_hat_100 <- c(mean(x_i), p_hat_100)
}
p_hatb_10 <- (p_hatb_10 - p)^2
p_hat_10 <- (p_hat_10 - p)^2
p_hatb_100 <- (p_hatb_100 - p)^2
p_hat_100 <- (p_hatb_100 - p)^2

P.data <- data.frame(p_hatb_10, p_hat_10, p_hatb_100, p_hat_100) 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian", aes(p_hat_10, colour= 'MLE Estimator, n = 10')) +
  geom_density(kernel = "gaussian", aes(p_hatb_10, colour= 'Bayesian Estimator, n = 10')) +
  labs(title = "Transformed Estimator Given p = 0.1, n = 10", x = "Estimator") 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian",aes(p_hat_100, colour= 'MLE Estimator, n = 100')) +
  geom_density(kernel = "gaussian",aes(p_hatb_100, colour= 'Bayesian Estimator, n = 100')) +
  labs(title = "Transformed Estimator Given p = 0.1, n = 100", x = "Estimator") 
```

The above produces some frequency plots for the corresponding Bayesian and MLE estimaotrs under sample size $10$ and $100$, for $p = 0.1$.  Below are some more plots made in identical manner for $p = 0.25, 0.5, 0.75, 0.9$.

```{r, echo = FALSE, fig.height = 3, fig.width = 6.5, fig.align='center'}
# Next p-value
p = 0.25

#first n value
n <- 10
p_hatb_10 <- p_hat_10 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_10 <- c((sum(x_i)+10)/(n+20), p_hatb_10) 
  p_hat_10 <- c(mean(x_i), p_hat_10)
}
# second n value
n <- 100
p_hatb_100 <- p_hat_100 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_100 <- c((sum(x_i)+10)/(n+20), p_hatb_100) 
  p_hat_100 <- c(mean(x_i), p_hat_100)
}
p_hatb_10 <- (p_hatb_10 - p)^2
p_hat_10 <- (p_hat_10 - p)^2
p_hatb_100 <- (p_hatb_100 - p)^2
p_hat_100 <- (p_hatb_100 - p)^2

P.data <- data.frame(p_hatb_10, p_hat_10, p_hatb_100, p_hat_100) 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian", aes(p_hat_10, colour= 'MLE Estimator, n = 10')) +
  geom_density(kernel = "gaussian", aes(p_hatb_10, colour= 'Bayesian Estimator, n = 10')) +
  labs(title = "Transformed Estimator Given p = 0.25, n = 10", x = "Estimator") 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian",aes(p_hat_100, colour= 'MLE Estimator, n = 100')) +
  geom_density(kernel = "gaussian",aes(p_hatb_100, colour= 'Bayesian Estimator, n = 100')) +
  labs(title = "Transformed Estimator Given p = 0.25, n = 100", x = "Estimator") 
```

```{r, echo = FALSE, fig.height = 3, fig.width = 6.5, fig.align='center'}
# Next p-value
p = 0.5

#first n value
n <- 10
p_hatb_10 <- p_hat_10 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_10 <- c((sum(x_i)+10)/(n+20), p_hatb_10) 
  p_hat_10 <- c(mean(x_i), p_hat_10)
}
# second n value
n <- 100
p_hatb_100 <- p_hat_100 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_100 <- c((sum(x_i)+10)/(n+20), p_hatb_100) 
  p_hat_100 <- c(mean(x_i), p_hat_100)
}
p_hatb_10 <- (p_hatb_10 - p)^2
p_hat_10 <- (p_hat_10 - p)^2
p_hatb_100 <- (p_hatb_100 - p)^2
p_hat_100 <- (p_hatb_100 - p)^2

P.data <- data.frame(p_hatb_10, p_hat_10, p_hatb_100, p_hat_100) 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian", aes(p_hat_10, colour= 'MLE Estimator, n = 10')) +
  geom_density(kernel = "gaussian", aes(p_hatb_10, colour= 'Bayesian Estimator, n = 10')) +
  labs(title = "Transformed Estimator Given p = 0.5, n = 10", x = "Estimator") 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian",aes(p_hat_100, colour= 'MLE Estimator, n = 100')) +
  geom_density(kernel = "gaussian",aes(p_hatb_100, colour= 'Bayesian Estimator, n = 100')) +
  labs(title = "Transformed Estimator Given p = 0.5, n = 100", x = "Estimator") 
```

```{r, echo = FALSE, fig.height = 3, fig.width = 6.5, fig.align='center'}
# Next p-value
p = 0.75

#first n value
n <- 10
p_hatb_10 <- p_hat_10 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_10 <- c((sum(x_i)+10)/(n+20), p_hatb_10) 
  p_hat_10 <- c(mean(x_i), p_hat_10)
}
# second n value
n <- 100
p_hatb_100 <- p_hat_100 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_100 <- c((sum(x_i)+10)/(n+20), p_hatb_100) 
  p_hat_100 <- c(mean(x_i), p_hat_100)
}
p_hatb_10 <- (p_hatb_10 - p)^2
p_hat_10 <- (p_hat_10 - p)^2
p_hatb_100 <- (p_hatb_100 - p)^2
p_hat_100 <- (p_hatb_100 - p)^2

P.data <- data.frame(p_hatb_10, p_hat_10, p_hatb_100, p_hat_100) 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian", aes(p_hat_10, colour= 'MLE Estimator, n = 10')) +
  geom_density(kernel = "gaussian", aes(p_hatb_10, colour= 'Bayesian Estimator, n = 10')) +
  labs(title = "Transformed Estimator Given p = 0.75, n = 10", x = "Estimator") 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian",aes(p_hat_100, colour= 'MLE Estimator, n = 100')) +
  geom_density(kernel = "gaussian",aes(p_hatb_100, colour= 'Bayesian Estimator, n = 100')) +
  labs(title = "Transformed Estimator Given p = 0.75, n = 100", x = "Estimator") 
```

```{r, echo = FALSE, fig.height = 3, fig.width = 6.5, fig.align='center'}
# Next p-value
p = 0.9

#first n value
n <- 10
p_hatb_10 <- p_hat_10 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_10 <- c((sum(x_i)+10)/(n+20), p_hatb_10) 
  p_hat_10 <- c(mean(x_i), p_hat_10)
}
# second n value
n <- 100
p_hatb_100 <- p_hat_100 <- c()
for (i in c(1:10000)){
  x_i <- rbinom(n, 1, p)
  p_hatb_100 <- c((sum(x_i)+10)/(n+20), p_hatb_100) 
  p_hat_100 <- c(mean(x_i), p_hat_100)
}
p_hatb_10 <- (p_hatb_10 - p)^2
p_hat_10 <- (p_hat_10 - p)^2
p_hatb_100 <- (p_hatb_100 - p)^2
p_hat_100 <- (p_hatb_100 - p)^2

P.data <- data.frame(p_hatb_10, p_hat_10, p_hatb_100, p_hat_100) 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian", aes(p_hat_10, colour= 'MLE Estimator, n = 10')) +
  geom_density(kernel = "gaussian", aes(p_hatb_10, colour= 'Bayesian Estimator, n = 10')) +
  labs(title = "Transformed Estimator Given p = 0.9, n = 10", x = "Estimator") 

P.data %>% ggplot() + xlim(0, 1) +
  geom_density(kernel = "gaussian",aes(p_hat_100, colour= 'MLE Estimator, n = 100')) +
  geom_density(kernel = "gaussian",aes(p_hatb_100, colour= 'Bayesian Estimator, n = 100')) +
  labs(title = "Transformed Estimator Given p = 0.9, n = 100", x = "Estimator") 
```
The Bayesian estimator outperforms the MLE estimator in terms of the transformation as p gets larger (towards 1), and as sample size grows.