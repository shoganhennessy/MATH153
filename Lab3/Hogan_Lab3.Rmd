---
title: "Lab 3"
author: "Senan Hogan-H."
header-includes:
   - \usepackage{amsmath}
   - \usepackage{hyperref}
date: "8 March 2018"
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.align="center")
gc()
ls()
options(digits=4)
require(tidyverse)
set.seed(47)
```

## Question 1.

a. Define $s^2=\frac{1}{n}\sum(x_i-\bar{x})^2$.
\begin{multline} \\
\sum_{i=1}^n(x_i-\mu)^2 = \\
\sum_{i=1}^n( x_i^2 - 2\mu x_i +\mu^2) = \\
\sum_{i=1}^n x_i^2 - 2 \mu\sum_{i=1}^nx_i + n \mu^2 = \\
\sum_{i=1}^n x_i^2 - 2\bar{x}\sum_{i=1}^nx_i + n \bar{x} ^2 + n\bar{x}^2 - 2 \mu\sum_{i=1}^nx_i + n \mu^2 = \\
\sum_{i=1}^n(x_i^2 -2\bar{x}x_i+\bar{x}^2) + n(\bar{x}^2 - 2\mu\bar{x} + \mu^2) = \\
\sum_{i=1}^n (x_i-\bar{x})^2  + n(\bar{x}-\mu)^2 = \\
ns^2 + n(\bar{x}-\mu)^2 \\
\end{multline}

b. Start with a normal prior, $f(\mu)=\mathcal{N}(\mu_0,\sigma_0^2)$.

c. Start with a normal prior, $f(\mu)=\mathcal{N}(\mu_0,\sigma_0^2)$, where $\mu_0=\sigma_0=1$.  Suppose that the real distribution has a mean and standard deviation of 3, so that $\bar{x}=3$.
```{r, fig.height = 4, fig.width = 8, fig.align='center'}
x_bar <- sd <- 3
mu_0 <- 1
sd_0 <- 1

prob <- seq(0, 6, .01)
# First prior
x_0 <- dnorm(prob, mu_0, sd_0)

# Update with data sample of 10
n <- 10

sd_10 <- ((n/(sd^2) + 1/(sd_0^2)))^(-0.5)
mu_10 <- sd_10^2*((mu_0/(sd_0^2)) + (n*x_bar)/sd^2)

x_10 <- dnorm(prob, mu_10, sd_10)

# Update with another data sample of 100
n <- 100

sd_100 <- ((n/(sd^2) + 1/(sd_0^2)))^(-0.5)
mu_100 <- sd_100^2*((mu_0/(sd_0^2)) + (n*x_bar)/sd^2)

x_100 <- dnorm(prob, mu_100, sd_100)

data.frame(x_0, x_10, x_100, prob) %>% ggplot(aes(x= prob)) +
  geom_line(aes(y= x_0, colour = 'Prior Distribution')) +
  geom_line(aes(y= x_10, colour = 'Posterior Distrubtion after n=10 sample')) +
  geom_line(aes(y= x_100, colour = 'Posterior Distrubtion after n=100 sample')) +
  labs(title = "Density for Normal, mean of 3, Updated with two Samples",
       x = "mu", y = "Density")
rm(list = ls())
```

d.  Use a prior of the form $\mathcal{G}(\alpha_0, \beta_0)$ where $\alpha_0, \beta_0 > 0$ to estimate $\lambda$.

```{r, fig.height = 4, fig.width = 8, fig.align='center'}
prob <- seq(0, 10, .01)

alpha_0 <- 1
beta_0 <- 1
x_0 <- dgamma(prob, alpha_0, beta_0)

data.frame(x_0, prob) %>% ggplot(aes(x = prob)) +
  geom_line(aes(y = x_0, colour = 'alpha = beta = 1')) +
  labs(title = "Various Gamma Distributions, Used as Prior for Lamda",
       x = "lambda", y = "Density")
rm(list = ls())
```

e. For the prior, want $\sigma^2=4$, $P(\sigma^2 > 2 )=0.9$.

So that $\frac{\alpha_0 - 1}{\beta_0} = 4$, $pbeta(2, \alpha_0, \beta_0) = 0.9$
```{r}
x <- 2
# (alpha_0 - 1)/beta_0 = 4, so beta_0 = (alpha_0 - 1)/4
alpha_0 <- vector[i]
beta_0 <- (alpha_0 - 1)/4

# start with 1 to ensure alpha_0, beta_0 > 0
vector <- seq(1, 100, by = 0.01)
i <- 1

epsilson <- 0.1
while (abs(pgamma(x, alpha_0, beta_0) - 0.9) > epsilson){
  alpha_0 <- vector[i]
  beta_0 <- (alpha_0 - 1)/4
}

alpha_0
beta_0
pbeta(x, alpha_0, beta_0) # roughly = 0.9

rm(list = ls())
```

f. 
```{r}
# test data
x <- rnorm(10000, 0, 1) 

# test hyperparameters
alpha_0 <- 1
beta_0 <- 1


# function that will be defined.
Normal_estimator <- function (x, alpha_0, beta_0){
  
  return(mean(x))
}


```

g.

\vspace{.5in}Consulted the following resource in working on this exercise: \url{https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf}





